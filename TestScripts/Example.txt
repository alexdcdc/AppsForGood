We need to think about the human aspect of using AI in our everyday lives and how it will influence the ways in which we perceive and interact with one another, says communication scholar Jeff Hancock.

Since its public launch in November 2022, ChatGPT has captured the world’s attention, showing millions of users around the globe the extraordinary potential of artificial intelligence as it churns out human-sounding answers to requests ranging from the practical to the surreal.

It has drafted cover letters, composed lines of poetry, pretended to be William Shakespeare, crafted messages for dating app users to woo matches, and even written news articles, all with varying results.

Emerging out of these promising applications are ethical dilemmas as well. In a world increasingly dominated by AI-powered tools that can mimic human natural language abilities, what does it mean to be truthful and authentic?

Hancock has been tackling this issue and the impact of AI on interpersonal relationships in his research.

Hancock argues that the Turing test era is over: Bots now sound so real that it has become impossible for people to distinguish between humans and machines in conversations, which poses huge risks for manipulation and deception at mass scale. How then can these tools be used for good and not harm is a question that has Hancock and others worried.

While he sees the potential of AI to help how people do their work more effectively, Hancock sees pitfalls as well. Ultimately, he says, our challenge will be to develop AI that supports human goals and to educate people how best to use these new technologies in effective and ethical ways.

For several years now, Hancock has been examining how AI-mediated communication is transforming—and potentially, undermining—interpersonal relationships.

Here, he explains some of the challenges tools like ChatGPT pose and how they will shape our lives going forward.